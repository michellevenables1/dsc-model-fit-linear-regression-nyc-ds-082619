{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit in Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lesson, you'll learn how to evaluate your model results, and you'll learn methods to select the appropriate features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Analyze the results of regression and R-squared and adjusted R-squared \n",
    "* Understand and apply forward and backward predictor selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-squared and adjusted R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take another look at the model summary output for the `auto-mpg` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below reiterates the steps we've taken before: we've created dummies for our categorical variables and have log-transformed some of our continuous predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('auto-mpg.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0         130    3504          12.0   \n",
       "1  15.0          8         350.0         165    3693          11.5   \n",
       "2  18.0          8         318.0         150    3436          11.0   \n",
       "3  16.0          8         304.0         150    3433          12.0   \n",
       "4  17.0          8         302.0         140    3449          10.5   \n",
       "\n",
       "   model year  origin                   car name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>170</td>\n",
       "      <td>3563</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85</td>\n",
       "      <td>2587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>87</td>\n",
       "      <td>2672</td>\n",
       "      <td>17.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2430</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>95</td>\n",
       "      <td>2375</td>\n",
       "      <td>17.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>113</td>\n",
       "      <td>2234</td>\n",
       "      <td>12.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2648</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>215</td>\n",
       "      <td>4615</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4376</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>210</td>\n",
       "      <td>4382</td>\n",
       "      <td>13.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2605</td>\n",
       "      <td>19.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2640</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2395</td>\n",
       "      <td>18.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>85</td>\n",
       "      <td>2575</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2525</td>\n",
       "      <td>16.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2735</td>\n",
       "      <td>18.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2865</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1980</td>\n",
       "      <td>15.3</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.2</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1970</td>\n",
       "      <td>17.6</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>63</td>\n",
       "      <td>2125</td>\n",
       "      <td>14.7</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>70</td>\n",
       "      <td>2125</td>\n",
       "      <td>17.3</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2160</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2205</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>70</td>\n",
       "      <td>2245</td>\n",
       "      <td>16.9</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1965</td>\n",
       "      <td>15.0</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1965</td>\n",
       "      <td>15.7</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1995</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>6</td>\n",
       "      <td>181.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2945</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>6</td>\n",
       "      <td>262.0</td>\n",
       "      <td>85</td>\n",
       "      <td>3015</td>\n",
       "      <td>17.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2585</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>112</td>\n",
       "      <td>2835</td>\n",
       "      <td>14.7</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>4</td>\n",
       "      <td>144.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2665</td>\n",
       "      <td>13.9</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2370</td>\n",
       "      <td>13.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2950</td>\n",
       "      <td>17.3</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement  horsepower  weight  acceleration  model year  \\\n",
       "0            8         307.0         130    3504          12.0          70   \n",
       "1            8         350.0         165    3693          11.5          70   \n",
       "2            8         318.0         150    3436          11.0          70   \n",
       "3            8         304.0         150    3433          12.0          70   \n",
       "4            8         302.0         140    3449          10.5          70   \n",
       "5            8         429.0         198    4341          10.0          70   \n",
       "6            8         454.0         220    4354           9.0          70   \n",
       "7            8         440.0         215    4312           8.5          70   \n",
       "8            8         455.0         225    4425          10.0          70   \n",
       "9            8         390.0         190    3850           8.5          70   \n",
       "10           8         383.0         170    3563          10.0          70   \n",
       "11           8         340.0         160    3609           8.0          70   \n",
       "12           8         400.0         150    3761           9.5          70   \n",
       "13           8         455.0         225    3086          10.0          70   \n",
       "14           4         113.0          95    2372          15.0          70   \n",
       "15           6         198.0          95    2833          15.5          70   \n",
       "16           6         199.0          97    2774          15.5          70   \n",
       "17           6         200.0          85    2587          16.0          70   \n",
       "18           4          97.0          88    2130          14.5          70   \n",
       "19           4          97.0          46    1835          20.5          70   \n",
       "20           4         110.0          87    2672          17.5          70   \n",
       "21           4         107.0          90    2430          14.5          70   \n",
       "22           4         104.0          95    2375          17.5          70   \n",
       "23           4         121.0         113    2234          12.5          70   \n",
       "24           6         199.0          90    2648          15.0          70   \n",
       "25           8         360.0         215    4615          14.0          70   \n",
       "26           8         307.0         200    4376          15.0          70   \n",
       "27           8         318.0         210    4382          13.5          70   \n",
       "28           8         304.0         193    4732          18.5          70   \n",
       "29           4          97.0          88    2130          14.5          71   \n",
       "..         ...           ...         ...     ...           ...         ...   \n",
       "362          4         112.0          88    2605          19.6          82   \n",
       "363          4         112.0          88    2640          18.6          82   \n",
       "364          4         112.0          88    2395          18.0          82   \n",
       "365          4         112.0          85    2575          16.2          82   \n",
       "366          4         135.0          84    2525          16.0          82   \n",
       "367          4         151.0          90    2735          18.0          82   \n",
       "368          4         140.0          92    2865          16.4          82   \n",
       "369          4         105.0          74    1980          15.3          82   \n",
       "370          4          91.0          68    2025          18.2          82   \n",
       "371          4          91.0          68    1970          17.6          82   \n",
       "372          4         105.0          63    2125          14.7          82   \n",
       "373          4          98.0          70    2125          17.3          82   \n",
       "374          4         120.0          88    2160          14.5          82   \n",
       "375          4         107.0          75    2205          14.5          82   \n",
       "376          4         108.0          70    2245          16.9          82   \n",
       "377          4          91.0          67    1965          15.0          82   \n",
       "378          4          91.0          67    1965          15.7          82   \n",
       "379          4          91.0          67    1995          16.2          82   \n",
       "380          6         181.0         110    2945          16.4          82   \n",
       "381          6         262.0          85    3015          17.0          82   \n",
       "382          4         156.0          92    2585          14.5          82   \n",
       "383          6         232.0         112    2835          14.7          82   \n",
       "384          4         144.0          96    2665          13.9          82   \n",
       "385          4         135.0          84    2370          13.0          82   \n",
       "386          4         151.0          90    2950          17.3          82   \n",
       "387          4         140.0          86    2790          15.6          82   \n",
       "388          4          97.0          52    2130          24.6          82   \n",
       "389          4         135.0          84    2295          11.6          82   \n",
       "390          4         120.0          79    2625          18.6          82   \n",
       "391          4         119.0          82    2720          19.4          82   \n",
       "\n",
       "     origin  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "5         1  \n",
       "6         1  \n",
       "7         1  \n",
       "8         1  \n",
       "9         1  \n",
       "10        1  \n",
       "11        1  \n",
       "12        1  \n",
       "13        1  \n",
       "14        3  \n",
       "15        1  \n",
       "16        1  \n",
       "17        1  \n",
       "18        3  \n",
       "19        2  \n",
       "20        2  \n",
       "21        2  \n",
       "22        2  \n",
       "23        2  \n",
       "24        1  \n",
       "25        1  \n",
       "26        1  \n",
       "27        1  \n",
       "28        1  \n",
       "29        3  \n",
       "..      ...  \n",
       "362       1  \n",
       "363       1  \n",
       "364       1  \n",
       "365       1  \n",
       "366       1  \n",
       "367       1  \n",
       "368       1  \n",
       "369       2  \n",
       "370       3  \n",
       "371       3  \n",
       "372       1  \n",
       "373       1  \n",
       "374       3  \n",
       "375       3  \n",
       "376       3  \n",
       "377       3  \n",
       "378       3  \n",
       "379       3  \n",
       "380       1  \n",
       "381       1  \n",
       "382       1  \n",
       "383       1  \n",
       "384       3  \n",
       "385       1  \n",
       "386       1  \n",
       "387       1  \n",
       "388       2  \n",
       "389       1  \n",
       "390       1  \n",
       "391       1  \n",
       "\n",
       "[392 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "outcome = 'mpg'\n",
    "predictors = data.drop('mpg', axis=1)\n",
    "pred_sum = '+'.join(predictors.columns) #all features joined together +\n",
    "formula = outcome + '~' + pred_sum\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('car name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 392 entries, 0 to 391\n",
      "Data columns (total 8 columns):\n",
      "mpg             392 non-null float64\n",
      "cylinders       392 non-null int64\n",
      "displacement    392 non-null float64\n",
      "horsepower      392 non-null int64\n",
      "weight          392 non-null int64\n",
      "acceleration    392 non-null float64\n",
      "model year      392 non-null int64\n",
      "origin          392 non-null int64\n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 24.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2961\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-18-9b7faa5e8639>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    model = ols(formula=formula, data=data).fit()\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/model.py\"\u001b[0m, line \u001b[1;32m155\u001b[0m, in \u001b[1;35mfrom_formula\u001b[0m\n    missing=missing)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/formula/formulatools.py\"\u001b[0m, line \u001b[1;32m65\u001b[0m, in \u001b[1;35mhandle_formula_data\u001b[0m\n    NA_action=na_action)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/highlevel.py\"\u001b[0m, line \u001b[1;32m310\u001b[0m, in \u001b[1;35mdmatrices\u001b[0m\n    NA_action, return_type)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/highlevel.py\"\u001b[0m, line \u001b[1;32m165\u001b[0m, in \u001b[1;35m_do_highlevel_design\u001b[0m\n    NA_action)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/highlevel.py\"\u001b[0m, line \u001b[1;32m70\u001b[0m, in \u001b[1;35m_try_incr_builders\u001b[0m\n    NA_action)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/build.py\"\u001b[0m, line \u001b[1;32m689\u001b[0m, in \u001b[1;35mdesign_matrix_builders\u001b[0m\n    factor_states = _factors_memorize(all_factors, data_iter_maker, eval_env)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/build.py\"\u001b[0m, line \u001b[1;32m354\u001b[0m, in \u001b[1;35m_factors_memorize\u001b[0m\n    which_pass = factor.memorize_passes_needed(state, eval_env)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/eval.py\"\u001b[0m, line \u001b[1;32m474\u001b[0m, in \u001b[1;35mmemorize_passes_needed\u001b[0m\n    subset_names = [name for name in ast_names(self.code)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/eval.py\"\u001b[0m, line \u001b[1;32m474\u001b[0m, in \u001b[1;35m<listcomp>\u001b[0m\n    subset_names = [name for name in ast_names(self.code)\n",
      "  File \u001b[1;32m\"/opt/conda/envs/learn-env/lib/python3.6/site-packages/patsy/eval.py\"\u001b[0m, line \u001b[1;32m105\u001b[0m, in \u001b[1;35mast_names\u001b[0m\n    for node in ast.walk(ast.parse(code)):\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/conda/envs/learn-env/lib/python3.6/ast.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    car name\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = ols(formula=formula, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "acc = data['acceleration']\n",
    "logdisp = np.log(data['displacement'])\n",
    "loghorse = np.log(data['horsepower'])\n",
    "logweight = np.log(data['weight'])\n",
    "\n",
    "scaled_acc = (acc-min(acc))/(max(acc)-min(acc))\t\n",
    "scaled_disp = (logdisp-np.mean(logdisp))/np.sqrt(np.var(logdisp))\n",
    "scaled_horse = (loghorse-np.mean(loghorse))/(max(loghorse)-min(loghorse))\n",
    "scaled_weight = (logweight-np.mean(logweight))/np.sqrt(np.var(logweight))\n",
    "\n",
    "data_fin = pd.DataFrame([])\n",
    "data_fin['acc'] = scaled_acc\n",
    "data_fin['disp'] = scaled_disp\n",
    "data_fin['horse'] = scaled_horse\n",
    "data_fin['weight'] = scaled_weight\n",
    "cyl_dummies = pd.get_dummies(data['cylinders'], prefix='cyl', drop_first=True)\n",
    "yr_dummies = pd.get_dummies(data['model year'], prefix='yr', drop_first=True)\n",
    "orig_dummies = pd.get_dummies(data['origin'], prefix='orig', drop_first=True)\n",
    "mpg = data['mpg']\n",
    "data_fin = pd.concat([mpg, data_fin, cyl_dummies, yr_dummies, orig_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>orig_2</th>\n",
       "      <th>orig_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  acceleration    weight  orig_2  orig_3\n",
       "0  18.0      0.238095  0.720986       0       0\n",
       "1  15.0      0.208333  0.908047       0       0\n",
       "2  18.0      0.178571  0.651205       0       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ols = pd.concat([mpg, scaled_acc, scaled_weight, orig_dummies], axis=1)\n",
    "data_ols.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'mpg'\n",
    "predictors = data_ols.drop('mpg', axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 26 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:01:06</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   20.7608</td> <td>    0.688</td> <td>   30.181</td> <td> 0.000</td> <td>   19.408</td> <td>   22.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>    0.4124</td> <td>    0.639</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.844</td> <td>    1.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_3</th>       <td>    1.7218</td> <td>    0.653</td> <td>    2.638</td> <td> 0.009</td> <td>    0.438</td> <td>    3.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>    8.47</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Thu, 26 Sep 2019   Prob (F-statistic):          1.86e-107\n",
       "Time:                        13:01:06   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       20.7608      0.688     30.181      0.000      19.408      22.113\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_2           0.4124      0.639      0.645      0.519      -0.844       1.669\n",
       "orig_3           1.7218      0.653      2.638      0.009       0.438       3.005\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                         8.47\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(formula=formula, data=data_ols).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss some key metrics in the light of our output:\n",
    "- R-squared uses a baseline model which is the worst model. This baseline model does not make use of any independent variables to predict the value of dependent variable Y. Instead it uses the mean of the observed responses of dependent variable Y and always predicts this mean as the value of Y. The mathematical formula to calculate R-squared for a linear regression line is in terms of squared errors for the fitted model and the baseline model. In the formula below, $SS_{RES}$ is the residual sum of squared errors or our model, also known as $SSE$, which is the error between the real and predicted values. $SS_{TOT}$ is the difference between real and mean $y$ values.\n",
    "\n",
    "### $$ R^2 = 1-\\dfrac{SS_{RES}}{SS_{TOT}}=1 - \\dfrac{\\sum_i (y_i-\\hat{y_i})^2}{\\sum_i {(y_i-\\bar{y_i})^2}}$$\n",
    "\n",
    "-  The problem with $R^2$ is that, whichever predictor you **add** to your model irrespective of whether it will add any new information to the model, will increase your $R^2$ value. That is, the model tends to overfit if we only use $R^2$ as our model fitting criterion. This is why train-has test split is essential and why regularization techniques are used to refine more advanced regression models. Make sure to read [this blogpost](https://www.statisticshowto.datasciencecentral.com/adjusted-r2/) on the difference between the two to get a better sense to why use $R^2_{adj}$ !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parameter estimates and p-values\n",
    "\n",
    "Just like with simple linear regression, the parameters or coefficients we're calculating have a p-value or *significance* attached to them. The interpretation of the p-value for each parameter is exactly the same as for multiple regression: \n",
    "\n",
    "> The p-value represents the probability that the coefficient is actually zero.\n",
    "\n",
    "In the Statsmodels output, the p-value can be found in the column with name $P>|t|$. A popular threshold for the p-value is 0.05, where we $p<0.05$ denotes that a certain parameter is significant, and $p>0.05$ means that the parameter isn't significant.\n",
    "\n",
    "The two columns right to the p-value column represent the bounds associated with the 95% confidence interval. What this means is that, after having run the model, we are 95% certain that our parameter value is within the bounds of this interval. When you chose a p-value cut-off of 0.05, there is an interesting relationship between the 95% confidence interval and the p-value: If the 95% confidence does not include 0, the p-value will be smaller than 0.05, and the parameter estimate will be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which variables are most important when predicting the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how predictors influence the target, let's talk about selecting the right predictors for your model. It is reasonable to think that when having many potential predictors (sometimes 100s or 1000s of predictors can be available!) not only will adding all of them largely increase computation time, but it might even lead to inferior $R^2_{adj}$ or inferior predictions in general. There are several ways to approach variable selection, and we'll only touch upon this in an ad-hoc manner in this lesson. The most straightforward way is to run a model with each possible *combination* of variables and see which one results in the best metric of your choice, let's say, $R^2_{adj}$. \n",
    " \n",
    "> This is where your combinatorics knowledge comes in handy!\n",
    "\n",
    "Now, when you know about combinations, you know that the number of combinations can add up really quickly. \n",
    "\n",
    "\n",
    "> Imagine you have 6 variables. How many models can you create with 6 variables and all subsets of variables?\n",
    "\n",
    "You can create:\n",
    "- 1 model with all 6 variables\n",
    "- 6 models with just 5 variables: $\\dbinom{6}{5}$\n",
    "- 15 models with just 4 variables: $\\dbinom{6}{4}= \\dfrac{6!}{2!*4!}=15$\n",
    "- 20 models with 3 variables: $\\dbinom{6}{3}= \\dfrac{6!}{3!*3!} = 20$\n",
    "- 15 models with 2 variables: $\\dbinom{6}{2}= \\dfrac{6!}{4!*2!} = 15$\n",
    "- 6 models with 1 variable: $\\dbinom{6}{1}$\n",
    "- And, technically, 1 model with no predictors: this will return a model that simply returns the mean of $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that with just 6 variables, a so-called exhaustive search of all submodels results in having to evaluate *64 models*. Below, we'll describe two methods that can be used to select a submodel with the most appropriate features: **stepwise selection** on the one hand, and **feature ranking with recursive feature elimination** on the other hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepwise selection with p-values\n",
    "\n",
    "In stepwise selection, you start with an empty model (which only includes the intercept), and each time, the variable that has an associated parameter estimate with the lowest p-value is added to the model (forward step). After adding each new variable in the model, the algorithm will look at the p-values of all the other parameter estimates which were added to the model previously, and remove them if the p-value exceeds a certain value (backward step). The algorithm stops when no variables can be added or removed given the threshold values. \n",
    "\n",
    "For more information, it's worth having a look at the [wikipedia page on stepwise regression](https://en.wikipedia.org/wiki/Stepwise_regression).\n",
    "\n",
    "Unfortunately, stepwise selection is not readily available a Python library just yet. [This stackexchange post](https://datascience.stackexchange.com/questions/937/does-scikit-learn-have-forward-selection-stepwise-regression-algorithm), however, presents the code to do a stepwise selection in statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  weight                         with p-value 1.16293e-107\n",
      "Add  acceleration                   with p-value 0.000646572\n",
      "Add  orig_3                         with p-value 0.0091813\n",
      "resulting features:\n",
      "['weight', 'acceleration', 'orig_3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(predictors, data_fin['mpg'], verbose=True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the stepwise selection on our small auto-mpg example (just starting with the predictors weight, acceleration and the origin categorical levels), we end up with a model that just keeps weight, acceleration, and orig_3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn also provides a few [functionalities for feature selection](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection). Their *Feature Ranking with Recursive Feature Elimination* selects the pre-specified $n$ most important features. This means you must specify the number of features to retail. If this number is not provided, half are used by default. See [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) for more information on how the algorithm works.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select=3)\n",
    "selector = selector.fit(predictors, data_fin['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `.support_` attribute tells you which variables are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `.ranking_` shows the ranking of the features, selected features are assigned rank 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling `.estimator_` on the RFE object, you can get access to the parameter estimates through `.coef_` and `.intercept`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.11183657 -5.95285464  1.53951788]\n",
      "20.841013816401656\n"
     ]
    }
   ],
   "source": [
    "estimators = selector.estimator_\n",
    "print(estimators.coef_)\n",
    "print(estimators.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the regression coefficients and intercept are slightly different. This is because only the three most important features were used in the model instead of the original four features. If you pass `n_features_to_select=4`, you should get the original coefficients.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward selection using adjusted R-squared\n",
    "\n",
    "[This resource](https://planspace.org/20150423-forward_selection_with_statsmodels/) provides code for a forward selection procedure (much like stepwise selection, but without a backward pass), but this time looking at the adjusted R-squared to make decisions on which variable to add to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! In this lesson, you learned about how you can perform selection methods using p-values and adjusted R-squared."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
